{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import to_categorical, img_to_array\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Input, concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from ml_logic.preprocessor import data_balancing, create_model, load_and_preprocess_image, image_augmentation, disease_categorization, num_cols, create_model_stage2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Datasets\n",
    "\n",
    "train = pd.read_csv('../data/RFMiD_Training_Labels.csv').set_index('ID')\n",
    "test = pd.read_csv('../data/RFMiD_Testing_Labels.csv').set_index('ID')\n",
    "eval = pd.read_csv('../data/RFMiD_Validation_Labels.csv').set_index('ID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Data\n",
    "\n",
    "X_train = disease_categorization(table_link='../data/')\n",
    "y_train = X_train\n",
    "X_eval  = eval.drop(columns='Disease_Risk')\n",
    "y_eval = eval['Disease_Risk']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      DR  MH  DN  ODC  Others\n",
      "ID                           \n",
      "309    0   0   0    0       1\n",
      "1541   1   0   0    0       0\n",
      "1662   1   0   0    0       0\n",
      "1671   0   0   0    0       1\n",
      "1148   0   0   0    0       1\n",
      "(1061, 5)\n",
      "      DR  MH  DN  ODC  Others\n",
      "ID                           \n",
      "1370   0   0   0    1       0\n",
      "226    0   0   1    0       0\n",
      "1415   1   0   0    0       0\n",
      "847    0   0   0    0       1\n",
      "242    1   0   0    0       0\n",
      "(1061, 5)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.sample(5))\n",
    "print(X_train.shape)\n",
    "print(y_train.sample(5))\n",
    "print(y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Images\n",
    "\n",
    "image_folder = '../data/training_images'\n",
    "eval_image_folder = '../data/eval_images'\n",
    "images = np.array([load_and_preprocess_image(row_id, image_folder) for row_id in X_train.index])\n",
    "eval_images = np.array([load_and_preprocess_image(row_id, eval_image_folder) for row_id in X_eval.index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(images[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(eval_images[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1061, 224, 224, 3)\n",
      "(640, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(images.shape)\n",
    "print(eval_images.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment Images\n",
    "\n",
    "# augmented_images = image_augmentation(images)\n",
    "# augmented_eval_images = image_augmentation(eval_images)\n",
    "# print(augmented_images.shape)\n",
    "# print(augmented_eval_images.shape)\n",
    "\n",
    "# plt.imshow(augmented_images[0])\n",
    "# plt.imshow(augmented_eval_images[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when comiling, it's categorical cross entropy instead of binary cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 21:34:39.960758: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-12-04 21:34:39.961220: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-12-04 21:34:39.961437: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (LAPTOP-R72GEULP): /proc/driver/nvidia/version does not exist\n",
      "2023-12-04 21:34:39.969431: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = create_model_stage2((224,224,3), last_layer_neurons=num_cols(X_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 220, 220, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 110, 110, 64)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 774400)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 12)                9292812   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                832       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,313,361\n",
      "Trainable params: 9,313,361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopper = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    min_delta=0.05,\n",
    "    patience=10,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    augmented_images, y_train,\n",
    "    validation_data=(augmented_eval_images, y_eval),\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stopper]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(augmented_eval_images, y_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
