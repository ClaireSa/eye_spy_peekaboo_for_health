{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-25 18:37:02.010508: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-25 18:37:02.373925: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-11-25 18:37:02.373948: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-11-25 18:37:02.450564: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-25 18:37:04.940379: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-11-25 18:37:04.940518: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-11-25 18:37:04.940532: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import to_categorical, img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Input, concatenate\n",
    "from ml_logic.preprocessor import data_balancing, create_augmented_model\n",
    "from ml_logic.preprocessor import load_and_preprocess_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/RFMiD_Training_Labels.csv').set_index('ID')\n",
    "test = pd.read_csv('../data/RFMiD_Testing_Labels.csv').set_index('ID')\n",
    "eval = pd.read_csv('../data/RFMiD_Validation_Labels.csv').set_index('ID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
<<<<<<< HEAD
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Disease_Risk', 'DR', 'ARMD', 'MH', 'DN', 'MYA', 'BRVO', 'TSLN', 'ERM',\n",
       "       'LS', 'MS', 'CSR', 'ODC', 'CRVO', 'TV', 'AH', 'ODP', 'ODE', 'ST',\n",
       "       'AION', 'PT', 'RT', 'RS', 'CRS', 'EDN', 'RPEC', 'MHL', 'RP', 'CWS',\n",
       "       'CB', 'ODPM', 'PRH', 'MNF', 'HR', 'CRAO', 'TD', 'CME', 'PTCR', 'CF',\n",
       "       'VH', 'MCA', 'VS', 'BRAO', 'PLQ', 'HPED', 'CL'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
=======
>>>>>>> dd02d8e6a082703f0feb92af466ab215ee264dd5
   "outputs": [],
   "source": [
    "# X_train = train.drop(columns='Disease_Risk')\n",
    "X_train = data_balancing(table_link='../data/')\n",
    "y_train = train['Disease_Risk']\n",
    "X_eval  = eval.drop(columns='Disease_Risk')\n",
    "y_eval = eval['Disease_Risk']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
<<<<<<< HEAD
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DR</th>\n",
       "      <th>ARMD</th>\n",
       "      <th>MH</th>\n",
       "      <th>DN</th>\n",
       "      <th>MYA</th>\n",
       "      <th>BRVO</th>\n",
       "      <th>TSLN</th>\n",
       "      <th>ERM</th>\n",
       "      <th>LS</th>\n",
       "      <th>MS</th>\n",
       "      <th>...</th>\n",
       "      <th>CME</th>\n",
       "      <th>PTCR</th>\n",
       "      <th>CF</th>\n",
       "      <th>VH</th>\n",
       "      <th>MCA</th>\n",
       "      <th>VS</th>\n",
       "      <th>BRAO</th>\n",
       "      <th>PLQ</th>\n",
       "      <th>HPED</th>\n",
       "      <th>CL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     DR  ARMD  MH  DN  MYA  BRVO  TSLN  ERM  LS  MS  ...  CME  PTCR  CF  VH  \\\n",
       "ID                                                   ...                      \n",
       "335   0     0   1   0    0     0     0    0   0   0  ...    0     0   0   0   \n",
       "\n",
       "     MCA  VS  BRAO  PLQ  HPED  CL  \n",
       "ID                                 \n",
       "335    0   0     0    0     0   0  \n",
       "\n",
       "[1 rows x 45 columns]"
=======
      "text/plain": [
       "(802, 224, 224, 3)"
>>>>>>> dd02d8e6a082703f0feb92af466ab215ee264dd5
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_folder = '../data/train_images'\n",
    "images = np.array([load_and_preprocess_image(row_id, image_folder) for row_id in X_train.index])\n",
    "# images = np.array([load_and_preprocess_image(X_train.iloc[0].ID, image_folder)])\n",
    "images.shape\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(image_id, image_folder, target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Load and preprocess an image given its ID.\n",
    "    \"\"\"\n",
    "    image_path = os.path.join(image_folder, f'{image_id}.png')\n",
    "    image = load_img(image_path, target_size=target_size)\n",
    "    image = img_to_array(image)\n",
    "    image = image / 255.0\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = '../data/training_images'\n",
    "images = np.array([load_and_preprocess_image(row_id, image_folder) for row_id in X_train.index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
=======
   "execution_count": null,
>>>>>>> dd02d8e6a082703f0feb92af466ab215ee264dd5
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_image_folder = '../data/eval_images'\n",
    "eval_images = np.array([load_and_preprocess_image(row_id, image_folder) for row_id in X_eval.index])\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
=======
   "execution_count": null,
>>>>>>> dd02d8e6a082703f0feb92af466ab215ee264dd5
   "metadata": {},
   "outputs": [],
   "source": [
    "image_input = Input(shape=(224, 224, 3))\n",
    "\n",
    "create_augmented_model\n",
    "x = Conv2D(32, (3, 3), activation='relu')(image_input)\n",
    "x = MaxPooling2D(2, 2)(x)\n",
    "x = Flatten()(x)\n",
    "\n",
    "\n",
    "#  NOTE: row_input would cause data leakage so it's been commented out.\n",
    "\n",
    "# row_input = Input(shape=(X_train.shape[1],))\n",
    "# y = Dense(64, activation='relu')(row_input)\n",
    "\n",
    "# combined = concatenate([x, y])\n",
    "\n",
    "z = Dense(12, activation='relu')(x)\n",
    "z = Dense(64, activation='relu')(z)\n",
    "z = Dense(1, activation='sigmoid')(z)\n",
    "\n",
    "\n",
    "model = Model(inputs=image_input, outputs=z)\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
=======
   "execution_count": null,
>>>>>>> dd02d8e6a082703f0feb92af466ab215ee264dd5
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 111, 111, 32)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 394272)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 12)                4731276   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                832       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4733069 (18.06 MB)\n",
      "Trainable params: 4733069 (18.06 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
=======
   "execution_count": null,
>>>>>>> dd02d8e6a082703f0feb92af466ab215ee264dd5
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60/60 [==============================] - 13s 203ms/step - loss: 0.5317 - accuracy: 0.7688 - val_loss: 0.5628 - val_accuracy: 0.7906\n",
      "Epoch 2/10\n",
      "60/60 [==============================] - 12s 193ms/step - loss: 0.4585 - accuracy: 0.8083 - val_loss: 0.5840 - val_accuracy: 0.7906\n",
      "Epoch 3/10\n",
      "60/60 [==============================] - 12s 191ms/step - loss: 0.4301 - accuracy: 0.8203 - val_loss: 0.6531 - val_accuracy: 0.7906\n",
      "Epoch 4/10\n",
      "60/60 [==============================] - 14s 226ms/step - loss: 0.4320 - accuracy: 0.8177 - val_loss: 0.8325 - val_accuracy: 0.7906\n",
      "Epoch 5/10\n",
      "60/60 [==============================] - 13s 214ms/step - loss: 0.4125 - accuracy: 0.8240 - val_loss: 0.6672 - val_accuracy: 0.7906\n",
      "Epoch 6/10\n",
      "60/60 [==============================] - 12s 198ms/step - loss: 0.4115 - accuracy: 0.8313 - val_loss: 0.5341 - val_accuracy: 0.7906\n",
      "Epoch 7/10\n",
      "60/60 [==============================] - 13s 208ms/step - loss: 0.4166 - accuracy: 0.8286 - val_loss: 0.5651 - val_accuracy: 0.7906\n",
      "Epoch 8/10\n",
      "60/60 [==============================] - 12s 199ms/step - loss: 0.3857 - accuracy: 0.8370 - val_loss: 0.7207 - val_accuracy: 0.7906\n",
      "Epoch 9/10\n",
      "60/60 [==============================] - 12s 200ms/step - loss: 0.3820 - accuracy: 0.8359 - val_loss: 0.5978 - val_accuracy: 0.7891\n",
      "Epoch 10/10\n",
      "60/60 [==============================] - 12s 200ms/step - loss: 0.3646 - accuracy: 0.8417 - val_loss: 0.6031 - val_accuracy: 0.7656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x29540ba00>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    images, y_train,\n",
    "    validation_data=(eval_images, y_eval),\n",
    "    epochs=10,\n",
    "    batch_size=32\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
=======
   "execution_count": null,
>>>>>>> dd02d8e6a082703f0feb92af466ab215ee264dd5
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 1s 54ms/step - loss: 0.6031 - accuracy: 0.7656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6031017303466797, 0.765625]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(eval_images, y_eval)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lewagon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
